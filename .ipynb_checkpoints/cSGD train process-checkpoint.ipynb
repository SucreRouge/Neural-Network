{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "torch.manual_seed(1) #reproducible\n",
    "EPOCH = 4\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist', #保存位置\n",
    "    train=True, #training set\n",
    "    transform=torchvision.transforms.ToTensor(), #converts a PIL.Image to torch.FloatTensor(C*H*W) in range(0.0,1.0)\n",
    "    download=True\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='./MNIST',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(learning_rate,u0,idx):\n",
    "    torch.manual_seed(27)\n",
    "    # network structure\n",
    "    class CNN(nn.Module):\n",
    "        def __init__(self,D_in,H,D_out):\n",
    "            super(CNN, self).__init__()\n",
    "            self.fc1 = nn.Linear(D_in,H)\n",
    "            torch.nn.init.normal(self.fc1.weight, mean=0, std=0.01)\n",
    "            #nn.init.xavier_normal(self.fc1.weight,gain = 1)\n",
    "            nn.init.constant(self.fc1.bias, 0.1)\n",
    "        \n",
    "            self.fc2 = nn.Linear(H,D_out)\n",
    "            torch.nn.init.normal(self.fc2.weight, mean=0, std=0.01)\n",
    "            #nn.init.xavier_normal(self.fc2.weight, gain = 1)\n",
    "            nn.init.constant(self.fc2.bias, 0.1)\n",
    "           # self.out = nn.Linear(10,10)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = x.view(-1, 784)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.softmax(self.fc2(x))\n",
    "            output = x\n",
    "            #output = self.out(x)\n",
    "            return output\n",
    "\n",
    "    D_in,H,D_out = 784,10,10\n",
    "    cnn = CNN(D_in,H,D_out)\n",
    "\n",
    "    # initial hyperpaameter\n",
    "    learning_rate = 0.2\n",
    "    u0 = 0.5\n",
    "    #loss function:cross-entropy with l2 regularizaiton\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    # inital all using viariables\n",
    "    EMAg = []\n",
    "    EMAg_2 = []\n",
    "    EMAx = []\n",
    "    EMAx_2 = []\n",
    "    EMAxg = []\n",
    "    EMAu = []\n",
    "    beta = []\n",
    "\n",
    "    # training iteration\n",
    "    for epoch in range(EPOCH):\n",
    "        running_loss = 0.0                        # loss to show\n",
    "        #training each mini-batch in dataloader\n",
    "        for i, data in enumerate(train_loader,0):\n",
    "           # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            cnn.zero_grad()\n",
    "\n",
    "            # forward + backward\n",
    "            outputs = cnn(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "       \n",
    "            # implementation of cSGD algo\n",
    "            for index,params in enumerate(cnn.parameters(),0):\n",
    "            \n",
    "                #update parameters process\n",
    "                if(i==0 and epoch==0):\n",
    "                    #lists store EMA of weight_grad, weight_grad_square, weight, and weight_square\n",
    "                \n",
    "                    EMAg.append(torch.Tensor(params.size()))\n",
    "                    EMAx.append(torch.Tensor(params.size()))\n",
    "                    EMAx_2.append(torch.Tensor(params.size()))\n",
    "                    EMAg_2.append(torch.Tensor(params.size()))\n",
    "                    EMAxg.append(torch.Tensor(params.size()))\n",
    "                \n",
    "                    n = params.dim()\n",
    "                    if n ==1:\n",
    "                        for item in range(0,params.size()[0]):\n",
    "                            EMAg[index][item] = params.grad.data[item]\n",
    "                            EMAx[index][item] = params.data[item]\n",
    "                            EMAg_2[index][item] = params.grad.data[item]**2\n",
    "                            EMAx_2[index][item] = params.data[item]**2\n",
    "                            EMAxg[index][item] = params.data[item]*params.grad.data[item]**2\n",
    "                    \n",
    "                    if n ==2:\n",
    "                    \n",
    "                        for item1 in range(0,params.size()[0]):\n",
    "                            for item2 in range(0,params.size()[1]):\n",
    "                                EMAg[index][item1,item2] = params.grad.data[item1,item2]\n",
    "                                EMAx[index][item1,item2] = params.data[item1,item2]\n",
    "                                EMAg_2[index][item1,item2] = params.grad.data[item1,item2]**2\n",
    "                                EMAx_2[index][item1,item2] = params.data[item1,item2]**2\n",
    "                                EMAxg[index][item1,item2] = params.data[item1,item2]*params.grad.data[item1,item2]\n",
    "                \n",
    "                    #lists store EMA of u and beta\n",
    "                    EMAu.append(torch.Tensor(params.size()))\n",
    "                    beta.append(torch.ones(params.size())*0.9)\n",
    "                    EMAu[index] = torch.ones(EMAu[index].size())*u0\n",
    "                    #print(EMAg[index][0,64])\n",
    "                    #print(EMAg_2[index][0,1])\n",
    "                else:\n",
    "                    one = torch.ones(params.size())\n",
    "                    #print(EMAg_2[index][0,1])\n",
    "                    #update EMA\n",
    "                    EMAg[index] = (beta[index])*EMAg[index]+(one-beta[index])*params.grad.data\n",
    "                    EMAg_2[index] = (beta[index])*EMAg_2[index] + (one-beta[index])*(params.grad.data.pow(2))\n",
    "                    EMAx[index] = (beta[index])*EMAx[index] + (one-beta[index])*params.data\n",
    "                    EMAx_2[index] = (beta[index])*EMAx_2[index]+(one-beta[index])*(params.data.pow(2))\n",
    "                    EMAxg[index] = (beta[index])*EMAxg[index] + (one-beta[index])*(params.grad.data*params.data)\n",
    "                \n",
    "                    #print(params.grad.data[0,64])\n",
    "                \n",
    "                    #cal a,b,sigma,u*\n",
    "                    n = params.dim()\n",
    "                    a = torch.Tensor(params.size())\n",
    "                    b = torch.Tensor(params.size())\n",
    "                    sigma = torch.Tensor(params.size())\n",
    "                    u = torch.Tensor(params.size())\n",
    "            \n",
    "            \n",
    "                    if n == 1:\n",
    "                        for item in range(0,params.size()[0]):\n",
    "                            #cal a\n",
    "                            if EMAxg[index][item]==EMAg[index][item]*EMAx[index][item]:\n",
    "                                 a[item] = 0\n",
    "                            elif (EMAx_2[index][item]-EMAx[index][item]**2)==0:\n",
    "                                 a[item] = 0\n",
    "                            else:\n",
    "                                 a[item] = (EMAxg[index][item]-EMAg[index][item]*EMAx[index][item])/(EMAx_2[index][item]-EMAx[index][item]**2)\n",
    "                        \n",
    "                        \n",
    "                            #cal sigma\n",
    "                            sigma[item] = EMAg_2[index][item] - EMAg[index][item]**2\n",
    "                        \n",
    "                            #cal u*\n",
    "                            if(a[item]<= 0):\n",
    "                                u[item] = 1\n",
    "                            else:\n",
    "                                if(EMAg[index][item]==0):\n",
    "                                    u[item] = 0.0\n",
    "                                elif(sigma[item]==0 or a[item]==0):\n",
    "                                    u[item] = 1.0\n",
    "                                else:\n",
    "                                    u[item] = min(1,(EMAg[index][item]**2)/(learning_rate*sigma[item]*a[item])) \n",
    "                            #update EMA u\n",
    "                            EMAu[index][item] = (1-beta[index][item])*EMAu[index][item] + beta[index][item]*u[item]\n",
    "                    \n",
    "                            #cal beta\n",
    "                            if (EMAg_2[index][item]==EMAg[index][item]**2):\n",
    "                                beta[index][item] = 0.9\n",
    "                            elif (EMAg_2[index][item]==0):\n",
    "                                beta[index][item] = 0.9\n",
    "                            else:\n",
    "                                beta[index][item] = 0.9+(0.999-0.9)*(EMAg_2[index][item]-EMAg[index][item]**2)/(EMAg_2[index][item])\n",
    "                        \n",
    "                    if n == 2:\n",
    "                    \n",
    "                        for item1 in range(0,params.size()[0]):\n",
    "                            for item2 in range(0,params.size()[1]):\n",
    "                                #cal a\n",
    "                                if ((EMAxg[index][item1,item2]-EMAg[index][item1,item2]*EMAx[index][item1,item2])==0):\n",
    "                                    a[item1,item2] = 0\n",
    "                                elif (EMAx_2[index][item1,item2]-EMAx[index][item1,item2]**2)==0:\n",
    "                                    a[item1,item2] = 0\n",
    "                                else:\n",
    "                                    a[item1,item2] =(EMAxg[index][item1,item2]-EMAg[index][item1,item2]*EMAx[index][item1,item2])/(EMAx_2[index][item1,item2]-EMAx[index][item1,item2]**2)            \n",
    "                                    #print(a[item1,item2])\n",
    "                        \n",
    "                                #cal sigma\n",
    "                                sigma[item1,item2] = EMAg_2[index][item1,item2] - math.pow(EMAg[index][item1,item2],2)\n",
    "                                #print(sigma[item1,item2])\n",
    "                                #if sigma[item1,item2]<0 :\n",
    "                                #    print(\"%d %d %d\"%(i,item1,item2))\n",
    "                                #    print(EMAg_2[index][item1,item2],EMAg[index][item1,item2])\n",
    "                                #cal u*\n",
    "                                if(a[item1,item2]<= 0):\n",
    "                                    u[item1,item2] = 1.0\n",
    "                                else:\n",
    "                                    if(EMAg[index][item1,item2]==0):\n",
    "                                        u[item1,item2] = 0.0\n",
    "                                    elif(sigma[item1,item2]==0 or a[item1,item2]==0):\n",
    "                                        u[item1,item2] = 1.0\n",
    "                                    else:\n",
    "                                        u[item1,item2] = min(1,(EMAg[index][item1,item2]**2)/(learning_rate*sigma[item1,item2]*a[item1,item2])) \n",
    "                                        #print(sigma[item1,item2]*a[item1,item2],EMAg[index][item1,item2]**2)\n",
    "                                        #print(EMAg[index][item1,item2]**2)\n",
    "                                        #print(a[item1,item2]*((EMAx[index][item1,item2]-b[item1,item2])**2)/(learning_rate*sigma[item1,item2]))\n",
    "                                #update EMAu\n",
    "                                EMAu[index][item1,item2] = (1-beta[index][item1,item2])*EMAu[index][item1,item2] + (beta[index][item1,item2])*u[item1,item2]\n",
    "                                #print(params.grad.data[5,5],params.data[5,5])\n",
    "                                #print(EMAx[index][0,5],EMAg[index][0,5],EMAu[index][0,5])\n",
    "                            \n",
    "                                #if i>=100:\n",
    "                                #    print(EMAu[index][item1,item2])\n",
    "                                #cal beta\n",
    "                                if EMAg_2[index][item1,item2]==EMAg[index][item1,item2]**2:\n",
    "                                    beta[index][item1,item2] = 0.9\n",
    "                                elif (EMAg_2[index][item1,item2]==0):\n",
    "                                    beta[index][item1,item2] = 0.9\n",
    "                                else:\n",
    "                                    beta[index][item1,item2] = 0.9+(0.999-0.9)*(EMAg_2[index][item1,item2]-EMAg[index][item1,item2]**2)/(EMAg_2[index][item1,item2])\n",
    "                        #print(params.grad.data[5,5],params.data[5,5],EMAu[index][5,5])\n",
    "                        #print(EMAx[index][5,5],EMAg[index][5,5],EMAu[index][5,5])\n",
    "                #update weight and bias\n",
    "            \n",
    "                params.data -= learning_rate *EMAu[index]* params.grad.data\n",
    "        \n",
    "            #print(\"%d %d\"%(epoch, i))\n",
    "            running_loss += loss.data[0]\n",
    "            if i % 100 == 99:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.8f' %(epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "                correct = 0.0\n",
    "                total = 0.0\n",
    "                for data in test_loader:\n",
    "                images, labels = data\n",
    "                outputs = cnn(Variable(images))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "                #result_data[idx][i/100+epoch*4] = correct/total\n",
    "                result_data1[idx][i/100+epoch*4] = correct/total\n",
    "    print('Finished Training')\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = cnn(Variable(images))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "    print('lr:%f u0:%f Accuracy: %f' % (learning_rate,u0,(correct / total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   400] loss: 2.00174031\n",
      "[2,   400] loss: 1.68377259\n",
      "[3,   400] loss: 1.58192106\n",
      "[4,   400] loss: 1.56229924\n",
      "Finished Training\n",
      "lr:0.400000 u0:0.003000 Accuracy: 0.916300\n",
      "[1,   400] loss: 1.96311093\n",
      "[2,   400] loss: 1.67176899\n",
      "[3,   400] loss: 1.57381722\n",
      "[4,   400] loss: 1.55711058\n",
      "Finished Training\n",
      "lr:0.500000 u0:0.003000 Accuracy: 0.919100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-658b06a04f9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#beta_w2 = 1/(10*10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#beta_b = 1/(10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-7992c73d2202>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(learning_rate, u0)\u001b[0m\n\u001b[1;32m    127\u001b[0m                                     \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                                     \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMAx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mEMAu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEMAu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mu0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(8)\n",
    "\n",
    "#random_u0 = -2*np.random.random(20)\n",
    "#random_lr = -1*np.random.random(20)\n",
    "x_u0 = [0.003,0.003,0.003]\n",
    "#x_u0 = np.sort(10**random_u0)\n",
    "x_lr = [0.4,0.5,0.6,0.7,0.9]\n",
    "result_data = np.zeros((len(x_u0),16))\n",
    "result_data1 = np.zeros((len(x_u0),16))\n",
    "#x_lr = np.sort(10**random_lr)\n",
    "#x = [0.002,0.04,0.3]\n",
    "for index in range(0, len(x_u0)):\n",
    "    lr = x_lr[index]\n",
    "    u0 = x_u0[index]\n",
    "    #beta_w1 = 1/(784*10)\n",
    "    #beta_w2 = 1/(10*10)\n",
    "    #beta_b = 1/(10)\n",
    "    train(lr,u0,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = result_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Xmax = np.zeros(43)\n",
    "Xmin = np.zeros(43)\n",
    "X_lrmax = np.zeros(43)\n",
    "X_lrmin = np.zeros(43)\n",
    "X_lrmedian = np.zeros(43)\n",
    "Xlr = y\n",
    "Xsum = np.zeros(30)\n",
    "\n",
    "# find max and min each test step to get area of accuracy distribution\n",
    "for n in range(0,43):\n",
    "    Xmax[n] = np.max(result_data[:,n])\n",
    "    Xmin[n] = np.min(result_data[:,n])\n",
    "\n",
    "# calculate area-under-curve and save it to Xsum\n",
    "for m in range(0,30):   \n",
    "    Xsum[m]  = np.sum(result_data[m,:])\n",
    "\n",
    "# find index of learning rate refer to max and min auc \n",
    "lr_min_i = np.argwhere(Xsum == np.min(Xsum))\n",
    "lr_max_i = np.argwhere(Xsum == np.max(Xsum))\n",
    "\n",
    "lr_min = Xlr[lr_min_i[0,0]]\n",
    "lr_max = Xlr[lr_max_i[0,0]]\n",
    "\n",
    "\n",
    "for n in range(0,43):\n",
    "    X_lrmin[n] = result_data[lr_min_i[0,0],n]\n",
    "    X_lrmax[n] = result_data[lr_max_i[0,0],n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "from matplotlib.ticker import  MultipleLocator\n",
    "matplotlib.use('Agg')\n",
    "x_index=np.arange(0,4,4.0/43)\n",
    "X_lrmedian = result_data[13,:]\n",
    "fig = plt.figure()\n",
    "plt.title(\"cSGD\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test Accu')\n",
    "plt.axis([0,4,0.0,1.0]) \n",
    "plt.plot(x_index,X_lrmedian,color = 'red',label='1e-2')\n",
    "plt.plot(x_index,X_lrmin,'r--',label='1e-3')\n",
    "plt.plot(x_index,X_lrmax,'r-.',label='2e-1')\n",
    "plt.fill_between(x_index,Xmin,Xmax,color = 'red',alpha = '0.1')\n",
    "plt.legend(loc='lower right',framealpha = 0.5)\n",
    "plt.savefig(\"cSGD new.png\") \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "adagrad_result_csv = pd.DataFrame(np.zeros((30,43)))\n",
    "adagrad_result_csv.iloc[:,:] = result_data\n",
    "adagrad_result_csv.to_csv('cSGD',index=False)\n",
    "training_csv = pd.read_csv('cSGD',index_col=0)\n",
    "training_csv\n",
    "\n",
    "np.save('cSGD-np.npy',result_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "from matplotlib.ticker import  MultipleLocator\n",
    "matplotlib.use('Agg')\n",
    "x_index=np.arange(0,4,4.0/43)\n",
    "X1 = result_data1[0,:]\n",
    "X2 = result_data1[1,:]\n",
    "X3 = result_data1[2,:]\n",
    "fig = plt.figure()\n",
    "plt.title(\"cSGD\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Test Accu')\n",
    "plt.axis([0,4,0.0,1.0]) \n",
    "plt.plot(x_index,X1,'r--',label='2e-3')\n",
    "plt.plot(x_index,X2,color = 'red',label='4e-2')\n",
    "plt.plot(x_index,X3,'r-.',label='3e-1')\n",
    "plt.fill_between(x_index,X1,X3,color = 'red',alpha = '0.1')\n",
    "plt.legend(loc='lower right',framealpha = 0.5)\n",
    "plt.savefig(\"cSGD para.png\") \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
